{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from os import listdir, mkdir, path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors, cm\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import medfilt\n",
    "from sklearn import tree\n",
    "import re\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following function shepherds files of various naming conventions into the correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_n_order_files(folder1,folder2,folder3,folder4,verbose=False):\n",
    "    files = listdir(folder1)\n",
    "    files1 = [ii for ii in files if ((not ii.__contains__('bkg')) & (ii.__contains__('csv')))]\n",
    "    seq1_1 = [ii for ii in files1 if re.match('Rxn1_[0-9]{4}_dz_bgsub.csv', ii)]\n",
    "    seq1_2 = [ii for ii in files1 if re.match('Rxn1_350_[0-9]{4}_dz_bgsub.csv', ii)]\n",
    "    seq1_3 = [ii for ii in files1 if re.match('Rxn1_cooling_[0-9]{4}_dz_bgsub.csv', ii)]\n",
    "    seq1 = []\n",
    "    seq1.extend(seq1_1)\n",
    "    seq1.extend(seq1_2)\n",
    "    seq1.extend(seq1_3)\n",
    "    files1 = [path.join(folder1,  ii) for ii in seq1]\n",
    "\n",
    "    files = listdir(folder2)\n",
    "    files2 = [ii for ii in files if ((not ii.__contains__('Bckgrd')) & (ii.__contains__('csv')))]\n",
    "    seq2_1 = [ii for ii in files2 if re.match('Rxn2_125_waxs_[0-9]{4}_dz_bgsub.csv', ii)]\n",
    "    seq2_2 = [ii for ii in files2 if re.match('Rxn2_350_waxs_[0-9]{4}_dz_bgsub.csv', ii)]\n",
    "    seq2_3 = [ii for ii in files2 if re.match('Rxn2_350_hold_[0-9]{4}_dz_bgsub.csv', ii)]\n",
    "    seq2_4 = [ii for ii in files2 if re.match('Rxn2_cool_[0-9]{4}_dz_bgsub.csv', ii)]\n",
    "    seq2 = []\n",
    "    seq2.extend(seq2_1)\n",
    "    seq2.extend(seq2_2)\n",
    "    seq2.extend(seq2_3)\n",
    "    seq2.extend(seq2_4)\n",
    "    files2 = [path.join(folder2,  ii) for ii in seq2]\n",
    "\n",
    "    files = listdir(folder3)\n",
    "    files3 = [ii for ii in files if ((not ii.__contains__('Bkg')) & (ii.__contains__('csv')))]\n",
    "    seq3_1 = [ii for ii in files3 if re.match('R3_125_[0-9]{4}_dz_bgsub.csv', ii)]\n",
    "    seq3_2 = [ii for ii in files3 if re.match('R3_350_[0-9]{4}_dz_bgsub.csv', ii)]\n",
    "    seq3_3 = [ii for ii in files3 if re.match('R3_350_II_[0-9]{4}_dz_bgsub.csv', ii)]\n",
    "    seq3_4 = [ii for ii in files3 if re.match('R3_350_cooling_[0-9]{4}_dz_bgsub.csv', ii)]\n",
    "    seq3 = []\n",
    "    seq3.extend(seq3_1)\n",
    "    seq3.extend(seq3_2)\n",
    "    seq3.extend(seq3_3)\n",
    "    seq3.extend(seq3_4)\n",
    "    files3 = [path.join(folder3,  ii) for ii in seq3]\n",
    "\n",
    "    files = listdir(folder4)\n",
    "    files4 = [ii for ii in files if ((not ii.__contains__('BG')) & (ii.__contains__('csv')))]\n",
    "    seq4_1 = [ii for ii in files4 if re.match('Rxn4_II_350_[0-9]{4}_dz_bgsub.csv', ii)]\n",
    "    seq4_2 = [ii for ii in files4 if re.match('Rxn4_350_hold_[0-9]{4}_dz_bgsub.csv', ii)]\n",
    "    seq4 = []\n",
    "    seq4.extend(seq4_1)\n",
    "    seq4.extend(seq4_2)\n",
    "    files4 = [path.join(folder4,  ii) for ii in seq4]\n",
    "\n",
    "    if verbose:\n",
    "        print \"Sequence lengths in folder 1: %i, %i, %i; expected: 100, 1000, 200\" % (len(seq1_1), len(seq1_2), len(seq1_3))\n",
    "        print \"Sequence lengths in folder 2: %i, %i, %i, %i; expected: 100, 1000, 668, 100\" % (len(seq2_1), len(seq2_2), len(seq2_3), len(seq2_4))\n",
    "        print \"Sequence lengths in folder 3: %i, %i, %i, %i; expected: 120, 500, 100, 100\" % (len(seq3_1), len(seq3_2), len(seq3_3), len(seq3_4))\n",
    "        print \"Sequence lengths in folder 4: %i, %i; expected: 100, 566\" % (len(seq4_1), len(seq4_2))\n",
    "    return files1, files2, files3, files4 #, seq1, seq2, seq3, seq4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following cell is one-time code for copying files from Sam's portable hard drive to my disk.  Don't execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from shutil import copy as filecopy\n",
    "\n",
    "folder1 = \"/Volumes/FreeAgent GoFlex Drive/SLAC/20170316_processed/R1/sample/raw/\"\n",
    "folder2 = \"/Volumes/FreeAgent GoFlex Drive/SLAC/20170316_processed/R2/sample/raw/\"\n",
    "folder3 = \"/Volumes/FreeAgent GoFlex Drive/SLAC/20170316_processed/R3/sample/raw/\"\n",
    "folder4 = \"/Volumes/FreeAgent GoFlex Drive/SLAC/20170316_processed/R4/sample/raw/\"\n",
    "\n",
    "outfolder1 = \"/Users/Amanda/Dropbox/Sam_data_20170316/R1\"\n",
    "outfolder2 = \"/Users/Amanda/Dropbox/Sam_data_20170316/R2\"\n",
    "outfolder3 = \"/Users/Amanda/Dropbox/Sam_data_20170316/R3\"\n",
    "outfolder4 = \"/Users/Amanda/Dropbox/Sam_data_20170316/R4\"\n",
    "\n",
    "def copy_to_disk():\n",
    "    files1, files2, files3, files4 = find_n_order_files(folder1,folder2,folder3,folder4)\n",
    "    outfiles1 = [path.join(outfolder1, path.split(ii)[1]) for ii in files1]\n",
    "    outfiles2 = [path.join(outfolder2, path.split(ii)[1]) for ii in files2]\n",
    "    outfiles3 = [path.join(outfolder3, path.split(ii)[1]) for ii in files3]\n",
    "    outfiles4 = [path.join(outfolder4, path.split(ii)[1]) for ii in files4]\n",
    "    for ii in range(len(files1)):\n",
    "        filecopy(files1[ii], outfiles1[ii])\n",
    "    for ii in range(len(files2)):\n",
    "        filecopy(files2[ii], outfiles2[ii])\n",
    "    for ii in range(len(files3)):\n",
    "        filecopy(files3[ii], outfiles3[ii])\n",
    "    for ii in range(len(files4)):\n",
    "        filecopy(files4[ii], outfiles4[ii])\n",
    "\n",
    "copy_to_disk()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For identifying & sequencing files under normal circumstances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder1 = \"/Users/Amanda/Dropbox/Sam_data_20170316/R1/\"\n",
    "folder2 = \"/Users/Amanda/Dropbox/Sam_data_20170316/R2/\"\n",
    "folder3 = \"/Users/Amanda/Dropbox/Sam_data_20170316/R3/\"\n",
    "folder4 = \"/Users/Amanda/Dropbox/Sam_data_20170316/R4/\"\n",
    "\n",
    "files1, files2, files3, files4 = find_n_order_files(folder1,folder2,folder3,folder4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make subfolders, if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_subfolders():\n",
    "    for ii in [folder1,folder2,folder3,folder4]:\n",
    "        if not path.isdir(path.join(ii, 'plots')):\n",
    "            mkdir(path.join(ii, 'plots'))\n",
    "\n",
    "mk_subfolders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readfiles(filenames):\n",
    "    nfiles = len(filenames)\n",
    "    ref_spec = np.loadtxt(filenames[0], delimiter=',')\n",
    "    ref_q, _ = ref_spec.T\n",
    "    intensity_image = np.zeros((ref_q.size,nfiles),dtype=float)\n",
    "    for ii in range(nfiles):\n",
    "        spectrum = np.loadtxt(filenames[ii], delimiter=',')\n",
    "        spec_q, spec_I = spectrum.T\n",
    "        if (spec_q != ref_q).any():\n",
    "            raise ValueError(\"Issue!  domain mismatch %s\" % filenames[ii])\n",
    "        intensity_image[:,ii] = spec_I\n",
    "    return intensity_image, ref_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intensity_image1, ref_spec1 = readfiles(files1)\n",
    "intensity_image2, ref_spec2 = readfiles(files2)\n",
    "intensity_image3, ref_spec3 = readfiles(files3)\n",
    "intensity_image4, ref_spec4 = readfiles(files4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document the state of the time series before removing outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc1 = path.join(folder1, 'plots', 'R1')\n",
    "loc2 = path.join(folder2, 'plots', 'R2')\n",
    "loc3 = path.join(folder3, 'plots', 'R3')\n",
    "loc4 = path.join(folder4, 'plots', 'R4')\n",
    "\n",
    "def waterfall_plot(diff_image, ref, loc=None, title_append=None, log=True):\n",
    "    nq, nfiles = diff_image.shape\n",
    "    qq,_ = ref.T\n",
    "    viridis = plt.get_cmap('viridis')\n",
    "    cNorm = colors.Normalize(vmin=0, vmax=nfiles)\n",
    "    scalarMap = cm.ScalarMappable(norm=cNorm, cmap=viridis)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot([qq[0],qq[-1]], [0,0], color='k',lw=1.5)\n",
    "    for ii in range(nfiles):\n",
    "        colorVal = scalarMap.to_rgba(ii)\n",
    "        ax.plot(qq, diff_image[:,ii], color=colorVal, lw=0.5)\n",
    "    title = 'Waterfall plot'\n",
    "    if title_append is not None:\n",
    "        title += title_append\n",
    "    ax.set_title(title)\n",
    "    if log:\n",
    "        ax.set_yscale('log')\n",
    "        lims = ax.axis()\n",
    "        ax.axis([lims[0], lims[1], 0.01, lims[3]])\n",
    "    if loc is not None:\n",
    "        print loc + '_waterfall.pdf'\n",
    "        fig.savefig(loc + '_waterfall.pdf')\n",
    "        #plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Amanda/Dropbox/Sam_data_20170316/R1/plots/R1_pre_outlier_removal_waterfall.pdf\n",
      "/Users/Amanda/Dropbox/Sam_data_20170316/R3/plots/R3_pre_outlier_removal_waterfall.pdf\n"
     ]
    }
   ],
   "source": [
    "waterfall_plot(intensity_image1, ref_spec1, loc1+'_pre_outlier_removal', ', R1 pre-removal')\n",
    "#waterfall_plot(intensity_image2, ref_spec2, loc2+'R2_pre_outlier_removal', ', R2 pre-removal')\n",
    "waterfall_plot(intensity_image3, ref_spec3, loc3+'_pre_outlier_removal', ', R3 pre-removal')\n",
    "#waterfall_plot(intensity_image4, ref_spec4, loc4+'R4_pre_outlier_removal', ', R4 pre-removal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ref_point1 = [4, 100, 500]\n",
    "\n",
    "def crude_filter(intensity_image, ref_spec, loc, ref_point=None):\n",
    "    # plot before\n",
    "    fig, ax = plt.subplots(1,3)\n",
    "    ax[0].imshow(np.log(intensity_image.T), cmap='viridis')\n",
    "    # separate into subtracted and not subtracted\n",
    "    nq, nfiles = intensity_image.shape\n",
    "    blank = np.ones((nq, nfiles),dtype=float)\n",
    "    file_index = np.arange(nfiles, dtype=int)\n",
    "    ref_q,_ = ref_spec.T\n",
    "    q_ref_index = min(np.where(ref_q > ref_point[0])[0])\n",
    "    subtracted = (intensity_image[q_ref_index,:] > ref_point[1]) & (intensity_image[q_ref_index,:] < ref_point[2])\n",
    "    kept_indices = np.where(subtracted)\n",
    "    ngood = subtracted.sum()\n",
    "    subtracted = np.array(subtracted[np.newaxis,:]*blank, dtype=bool)\n",
    "    good_spectra = intensity_image[subtracted].reshape(nq, ngood)\n",
    "    if ref_point is not None:\n",
    "        bad_spectra = intensity_image[~subtracted].reshape(nq, nfiles-ngood)\n",
    "    # require values be positive\n",
    "    floor = 0.01\n",
    "    good_spectra[np.where(good_spectra < floor)] = floor\n",
    "    if ref_point is not None:\n",
    "        bad_spectra[np.where(bad_spectra < floor)] = floor\n",
    "    else:\n",
    "        print \"RuntimeWarning: divide by zero coming up, don't worry about it\"\n",
    "        bad_spectra = np.zeros((nq,1))\n",
    "    # plot after\n",
    "    ax[1].imshow(np.log(good_spectra.T), cmap='viridis')\n",
    "    ax[2].imshow(np.log(bad_spectra.T), cmap='viridis')\n",
    "    ax[0].set_title('Before cleanup')\n",
    "    ax[0].axis('off')\n",
    "    ax[1].set_title('Subtracted, cleaned')\n",
    "    ax[1].axis('off')\n",
    "    ax[2].set_title('Unsubtracted, cleaned')\n",
    "    ax[2].axis('off')\n",
    "    fig.savefig(loc+\"_cleaning.pdf\")\n",
    "    waterfall_plot(good_spectra, ref_spec, loc+\"_subtracted\", \", cleaned spectra\")\n",
    "    if ref_point is not None:\n",
    "        waterfall_plot(bad_spectra, ref_spec, loc+\"_unsubtracted\", \", outlier spectra\")\n",
    "    return good_spectra, bad_spectra, kept_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Amanda/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "/Users/Amanda/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in log\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Amanda/Dropbox/Sam_data_20170316/R1/plots/R1_subtracted_waterfall.pdf\n",
      "/Users/Amanda/Dropbox/Sam_data_20170316/R1/plots/R1_unsubtracted_waterfall.pdf\n",
      "/Users/Amanda/Dropbox/Sam_data_20170316/R3/plots/R3_subtracted_waterfall.pdf\n"
     ]
    }
   ],
   "source": [
    "good_spectra1, bad_spectra1, kept_indices = crude_filter(intensity_image1, ref_spec1, loc1, ref_point1)\n",
    "good_spectra3 = intensity_image3\n",
    "waterfall_plot(good_spectra3, ref_spec3, loc3+\"_subtracted\", \", cleaned spectra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambdas1 = [3.09, 3.2, 3.66]\n",
    "lambdas3 = [2.78, 3.07, 3.22, 3.32, 4.49]\n",
    "\n",
    "lims1 = [[2.95,3.05,3.4,3.5],[3.45,3.55,3.9,4.0]]\n",
    "lims3 = [[2.5,2.6,2.95,3.05],[2.95,3.05,3.4,3.5],[4.2,4.3,4.7,4.8]]\n",
    "\n",
    "def linear(x, a, b):\n",
    "    return a + b*x\n",
    "\n",
    "def quadratic(x, a, b, c):\n",
    "    return a + b*x + c*x**2\n",
    "\n",
    "def cubic(x, a, b, c, d):\n",
    "    return a + b*x + c*x**2 + d*x**3\n",
    "\n",
    "def quartic(x, a, b, c, d, e):\n",
    "    return a + b*x + c*x**2 + d*x**3 + e*x**3\n",
    "\n",
    "def quintic(x, a, b, c, d, e, f):\n",
    "    return a + b*x + c*x**2 + d*x**3 + e*x**3 + f*x**5\n",
    "\n",
    "\n",
    "def basic_bg_local(image, func, p0, ref_spec, lims, loc):\n",
    "    qq,_ = ref_spec.T\n",
    "    nq, nfiles = image.shape\n",
    "    blank = np.ones(image.shape, dtype=bool)\n",
    "    subtracted_regions = []\n",
    "    for ii in range(len(lims)):\n",
    "        q1 = lims[ii][0]\n",
    "        q2 = lims[ii][1]\n",
    "        q3 = lims[ii][2]\n",
    "        q4 = lims[ii][3]\n",
    "        locale = ((qq > q1) & (qq < q4))\n",
    "        feature = ((qq > q2) & (qq < q3))\n",
    "        periphery = (locale & ~feature)\n",
    "        qlocale = qq[locale]\n",
    "        qperiphery = qq[periphery]\n",
    "        nlocale = locale.sum()\n",
    "        nfeature = feature.sum()\n",
    "        nperiphery = periphery.sum()\n",
    "        locale = image[locale[:,np.newaxis]*blank].reshape(nlocale,nfiles)\n",
    "        feature = image[feature[:,np.newaxis]*blank].reshape(nfeature,nfiles)\n",
    "        periphery = image[periphery[:,np.newaxis]*blank].reshape(nperiphery,nfiles)\n",
    "        waterfall_plot(locale, np.array([qlocale,qlocale]).T, loc+\"_local_%i\"%ii,', unsubtracted local',False)\n",
    "        subtracted = np.zeros(locale.shape,dtype=float)\n",
    "        for jj in range(nfiles):\n",
    "            popt, _ = curve_fit(func,qperiphery,periphery[:,jj],p0=p0)\n",
    "            subtracted[:,jj] = locale[:,jj] - func(qlocale,*popt)\n",
    "        waterfall_plot(subtracted+1, np.array([qlocale,qlocale]).T, loc+\"_local_subtracted_%i\"%ii,', subtracted local',False)\n",
    "        subtracted_regions.append([qlocale,subtracted])\n",
    "    return subtracted_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Amanda/Dropbox/Sam_data_20170316/R1/plots/R1_local_0_waterfall.pdf\n",
      "/Users/Amanda/Dropbox/Sam_data_20170316/R1/plots/R1_local_subtracted_0_waterfall.pdf\n",
      "/Users/Amanda/Dropbox/Sam_data_20170316/R1/plots/R1_local_1_waterfall.pdf\n",
      "/Users/Amanda/Dropbox/Sam_data_20170316/R1/plots/R1_local_subtracted_1_waterfall.pdf\n",
      "/Users/Amanda/Dropbox/Sam_data_20170316/R3/plots/R3_local_0_waterfall.pdf\n",
      "/Users/Amanda/Dropbox/Sam_data_20170316/R3/plots/R3_local_subtracted_0_waterfall.pdf\n",
      "/Users/Amanda/Dropbox/Sam_data_20170316/R3/plots/R3_local_1_waterfall.pdf\n",
      "/Users/Amanda/Dropbox/Sam_data_20170316/R3/plots/R3_local_subtracted_1_waterfall.pdf\n",
      "/Users/Amanda/Dropbox/Sam_data_20170316/R3/plots/R3_local_2_waterfall.pdf\n",
      "/Users/Amanda/Dropbox/Sam_data_20170316/R3/plots/R3_local_subtracted_2_waterfall.pdf\n"
     ]
    }
   ],
   "source": [
    "subtracted_regions1 = basic_bg_local(good_spectra1, cubic, [1,0,0,0], ref_spec1, lims1, loc1)\n",
    "subtracted_regions3 = basic_bg_local(good_spectra3, cubic, [1,0,0,0], ref_spec3, lims3, loc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gauss(x, a, x0, sigma):\n",
    "    #return (2*np.pi*sigma**2)**-0.5 * np.exp(-0.5*((x - x0)/sigma)**2)\n",
    "    return a * np.exp(-0.5*((x - x0)/sigma)**2)\n",
    "\n",
    "def residuals(x, y, func, pars):\n",
    "    return (((y - func(x, *pars))**2).mean())**0.5\n",
    "\n",
    "def manypeaks(x, *params):\n",
    "    # params pattern:  a0, x0, s0, a1, x1, s1...\n",
    "    params = np.array(params)\n",
    "    npeaks = params.size/3\n",
    "    y = np.zeros(x.shape,dtype=float)\n",
    "    for ii in range(npeaks):\n",
    "        ai,xi,si = params[3*ii:3*ii+3]\n",
    "        y += gauss(x,ai,xi,si)\n",
    "    return y\n",
    "\n",
    "def plotarray(nplots, arrange_vertical=True, sharex=False, sharey=False):\n",
    "    nplots = int(nplots)\n",
    "    print nplots\n",
    "    if nplots == 1:\n",
    "        fig, ax = plt.subplots()\n",
    "        return fig, np.array([ax])\n",
    "    if arrange_vertical:\n",
    "        nrows = int(np.ceil(nplots**0.5))\n",
    "        ncols = int(np.ceil(nplots/nrows))\n",
    "    else:\n",
    "        ncols = int(np.ceil(nplots**0.5))\n",
    "        nrows = int(np.ceil(nplots/ncols))\n",
    "    fig, ax = plt.subplots(nrows,ncols)\n",
    "    flatax = ax.ravel()\n",
    "    for ii in range(ax.size):\n",
    "        if ii > (nplots - 1):\n",
    "            flatax[ii].axis('off')\n",
    "    return fig, ax\n",
    "\n",
    "def sample_plot_array(n, q, data_seq, fit_seq=None):\n",
    "    fig,ax = plotarray(n, True, True, True)\n",
    "    flatax = ax.ravel()\n",
    "    N = len(data_seq)\n",
    "    indices = np.arange(n,dtype=int)*nfiles/n + int(0.5*nfiles)/n\n",
    "    print n, N, indices\n",
    "    for ii in range(n):\n",
    "        flatax[ii].plot(q, data_seq[:,indices[ii]], c='k',lw=1)\n",
    "        if fit_seq:\n",
    "            flatax[ii].plot(q, fit_seq[:,indices[ii]], c='b',lw=2)\n",
    "        #flatax[ii].axis('off')\n",
    "    fig.suptitle(\"Evolution of sequence\")\n",
    "'''\n",
    "    kk = 0\n",
    "    for ii in range(ax.shape[0]):\n",
    "        for jj in range(ax.shape[1]):\n",
    "            colorVal = scalarMap.to_rgba(indices[kk])\n",
    "            ax[ii,jj].plot(q, data_seq[:,indices[kk]], c=colorVal,lw=1)\n",
    "            if fit_seq is not None:\n",
    "                ax[ii,jj].plot(q, fit_seq[:,indices[kk]], c=colorVal,lw=2)\n",
    "            if (ii != ax.shape[0]-1):\n",
    "                ax[ii,jj].get_xaxis().set_ticks([])\n",
    "            if (jj != 0):\n",
    "                ax[ii,jj].get_yaxis().set_ticks([])\n",
    "            #flatax[ii].axis('off')\n",
    "            kk += 1\n",
    "'''\n",
    " \n",
    "\n",
    "def sample_plot_waterfall(n, q, data_seq, fit_seq=None):\n",
    "    fig,ax = plt.subplots()\n",
    "    nq,nfiles = data_seq.shape\n",
    "    indices = np.arange(n,dtype=int)*nfiles/n + int(0.5*nfiles)/n\n",
    "    viridis = plt.get_cmap('viridis')\n",
    "    cNorm = colors.Normalize(vmin=0, vmax=nfiles)\n",
    "    scalarMap = cm.ScalarMappable(norm=cNorm, cmap=viridis)\n",
    "\n",
    "    for ii in range(n):\n",
    "        colorVal = scalarMap.to_rgba(indices[ii])\n",
    "        ax.plot(q, data_seq[:,indices[ii]], color=colorVal, lw=1)\n",
    "        if fit_seq is not None:\n",
    "            ax.plot(q, fit_seq[:,indices[ii]], c=colorVal,lw=2)\n",
    "    fig.suptitle(\"Evolution of sequence\")\n",
    "    \n",
    "    \n",
    "def parameter_trace_display(params):\n",
    "    npars,nfiles = params.shape\n",
    "    viridis = plt.get_cmap('viridis')\n",
    "    cNorm = colors.Normalize(vmin=0, vmax=nfiles)\n",
    "    scalarMap = cm.ScalarMappable(norm=cNorm, cmap=viridis)\n",
    "    for ii in range(npars/3):\n",
    "        fig,axarray = plt.subplots(2,1)\n",
    "        a, x0, sigma = params[ii*3:ii*3+3,:]\n",
    "        for jj in range(nfiles):\n",
    "            if (a[jj]==0)&(x0[jj]==0)&(sigma[jj]==0):\n",
    "                continue\n",
    "            colorVal = scalarMap.to_rgba(jj)\n",
    "            axarray[0].plot(x0[jj],a[jj]*np.sqrt(2*np.pi)*sigma[jj],ls='none',lw=0.5,marker='.',color=colorVal)\n",
    "            axarray[1].plot(sigma[jj],a[jj],ls='none',lw=0.5,marker='.',color=colorVal)\n",
    "        axarray[0].set_xlabel('peak position, q')\n",
    "        axarray[0].set_ylabel('peak integrated intensity')\n",
    "        axarray[1].set_xlabel('peak width $\\sigma$')\n",
    "        axarray[1].set_ylabel('peak height')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameter_trace_display(fit_record_1_0)\n",
    "parameter_trace_display(fit_record_1_1)\n",
    "parameter_trace_display(fit_record_3_0)\n",
    "parameter_trace_display(fit_record_3_1a)\n",
    "parameter_trace_display(fit_record_3_1b)\n",
    "parameter_trace_display(fit_record_3_1c)\n",
    "parameter_trace_display(fit_record_3_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_plot_waterfall(16, subtracted_regions1[0][0], subtracted_regions1[0][1])\n",
    "sample_plot_waterfall(16, subtracted_regions1[1][0], subtracted_regions1[1][1])\n",
    "sample_plot_waterfall(16, subtracted_regions3[0][0], subtracted_regions3[0][1])\n",
    "sample_plot_waterfall(16, subtracted_regions3[1][0], subtracted_regions3[1][1])\n",
    "sample_plot_waterfall(16, subtracted_regions3[2][0], subtracted_regions3[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p0_1_0 = [70., 3.16, 0.04]\n",
    "bd_1_0 = [[0., 3.12, 0.02],\n",
    "          [120., 3.31, 0.07]]\n",
    "\n",
    "p0_1_1 = [30., 3.68, 0.04]\n",
    "bd_1_1 = [[0., 3.61, 0.02],\n",
    "          [55., 3.82, 0.07]]\n",
    "\n",
    "p0_3_0 = [50., 2.78, 0.025]\n",
    "bd_3_0 = [[0., 2.74, 0.01],\n",
    "          [60., 2.81, 0.06]]\n",
    "\n",
    "p0_3_1a = [75., 3.21, 0.035]\n",
    "bd_3_1a = [[0., 3.12, 0.02],\n",
    "           [90., 3.36, 0.07]]\n",
    "\n",
    "p0_3_1b = [75., 3.21, 0.035, 55., 3.31, 0.035]\n",
    "bd_3_1b = [[0., 3.12, 0.02, 0., 3.26, 0.02],\n",
    "           [90., 3.26, 0.07, 70., 3.36, 0.07]]\n",
    "\n",
    "p0_3_1c = [20., 3.12, 0.035, 75., 3.21, 0.035, 55., 3.31, 0.035]\n",
    "bd_3_1c = [[0., 3.05, 0.02, 0., 3.16, 0.02, 0., 3.26, 0.02],\n",
    "           [35., 3.16, 0.07, 90., 3.26, 0.07, 70., 3.36, 0.07]]\n",
    "\n",
    "p0_3_2 = [22., 4.48, 0.025]\n",
    "bd_3_2 = [[0., 4.44, 0.01],\n",
    "          [35., 4.53, 0.06]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def individual_fit(qq,image,func,p0,bd):\n",
    "    nq,nfiles = image.shape\n",
    "    fit_image = np.zeros(image.shape)\n",
    "    fit_record = np.zeros((len(p0),nfiles))\n",
    "    failcounter = 0\n",
    "    for ii in range(nfiles):\n",
    "        try:\n",
    "            popt,_ = curve_fit(func,qq,image[:,ii],p0=p0,bounds=bd)\n",
    "            p0=popt\n",
    "        except RuntimeError:\n",
    "            popt = 0*np.array(p0)\n",
    "            failcounter += 1\n",
    "        fit_image[:,ii] = func(qq,*popt)\n",
    "        fit_record[:,ii] = popt\n",
    "    if failcounter != 0:\n",
    "        print \"%i spectra did not converge to a solution.\" % failcounter\n",
    "    else:\n",
    "        print \"All spectra converged to a fit solution.\"\n",
    "    return fit_image, fit_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Amanda/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 spectra did not converge to a solution.\n",
      "All spectra converged to a fit solution.\n",
      "9 spectra did not converge to a solution.\n",
      "2 spectra did not converge to a solution.\n",
      "All spectra converged to a fit solution.\n",
      "1 spectra did not converge to a solution.\n",
      "2 spectra did not converge to a solution.\n"
     ]
    }
   ],
   "source": [
    "fit_image_1_0,fit_record_1_0 = individual_fit(subtracted_regions1[0][0],subtracted_regions1[0][1],gauss,p0_1_0,bd_1_0)\n",
    "fit_image_1_1,fit_record_1_1 = individual_fit(subtracted_regions1[1][0],subtracted_regions1[1][1],gauss,p0_1_1,bd_1_1)\n",
    "fit_image_3_0,fit_record_3_0 = individual_fit(subtracted_regions3[0][0],subtracted_regions3[0][1],gauss,p0_3_0,bd_3_0)\n",
    "fit_image_3_1a,fit_record_3_1a = individual_fit(subtracted_regions3[1][0],subtracted_regions3[1][1],gauss,p0_3_1a,bd_3_1a)\n",
    "fit_image_3_1b,fit_record_3_1b = individual_fit(subtracted_regions3[1][0],subtracted_regions3[1][1],manypeaks,p0_3_1b,bd_3_1b)\n",
    "fit_image_3_1c,fit_record_3_1c = individual_fit(subtracted_regions3[1][0],subtracted_regions3[1][1],manypeaks,p0_3_1c,bd_3_1c)\n",
    "fit_image_3_2,fit_record_3_2 = individual_fit(subtracted_regions3[2][0],subtracted_regions3[2][1],gauss,p0_3_2,bd_3_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_plot_waterfall(16, subtracted_regions1[0][0], subtracted_regions1[0][1],fit_image_1_0)\n",
    "sample_plot_waterfall(16, subtracted_regions1[1][0], subtracted_regions1[1][1],fit_image_1_1)\n",
    "sample_plot_waterfall(16, subtracted_regions3[0][0], subtracted_regions3[0][1],fit_image_3_0)\n",
    "sample_plot_waterfall(16, subtracted_regions3[1][0], subtracted_regions3[1][1],fit_image_3_1a)\n",
    "sample_plot_waterfall(16, subtracted_regions3[1][0], subtracted_regions3[1][1],fit_image_3_1b)\n",
    "sample_plot_waterfall(16, subtracted_regions3[1][0], subtracted_regions3[1][1],fit_image_3_1c)\n",
    "sample_plot_waterfall(16, subtracted_regions3[2][0], subtracted_regions3[2][1],fit_image_3_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "For comparing fitting options of q~3.2 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "waterfall_plot(subtracted_regions1[0][1], np.array([subtracted_regions1[0][0],subtracted_regions1[0][0]]).T, loc1+'_nah', title_append=None, log=False)\n",
    "waterfall_plot(subtracted_regions3[1][1], np.array([subtracted_regions3[1][0],subtracted_regions3[1][0]]).T, loc3+'_nah', title_append=None, log=False)\n",
    "\n",
    "parameter_trace_display(fit_record_1_0)\n",
    "parameter_trace_display(fit_record_3_1a)\n",
    "parameter_trace_display(fit_record_3_1b)\n",
    "parameter_trace_display(fit_record_3_1c)\n",
    "\n",
    "sample_plot_waterfall(16, subtracted_regions1[0][0], subtracted_regions1[0][1],fit_image_1_0)\n",
    "sample_plot_waterfall(16, subtracted_regions3[1][0], subtracted_regions3[1][1],fit_image_3_1a)\n",
    "sample_plot_waterfall(16, subtracted_regions3[1][0], subtracted_regions3[1][1],fit_image_3_1b)\n",
    "sample_plot_waterfall(16, subtracted_regions3[1][0], subtracted_regions3[1][1],fit_image_3_1c)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below:  Experimental code for using decision trees to seek background/feature distinction.  Not presently recommended for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_features_1():\n",
    "    qq,_ = ref_spec1.T\n",
    "    features = (((qq > 1.75) & (qq < 1.95)) | ((qq > 3.05) & (qq < 3.4)) | ((qq > 3.55) & (qq < 3.9)))\n",
    "    return features\n",
    "def initial_features_2():\n",
    "    qq,_ = ref_spec1.T\n",
    "    features = (((qq > 2.6) & (qq < 2.95)) | ((qq > 3.05) & (qq < 3.4)) | ((qq > 4.3) & (qq < 4.7)))\n",
    "    return features\n",
    "\n",
    "\n",
    "def grow(arr, nn):\n",
    "    arr = arr.astype('bool')\n",
    "    for ii in range(nn):\n",
    "        arr[1:,:] = arr[1:,:] | arr[:-1,:]\n",
    "        arr[:-1,:] = arr[1:,:] | arr[:-1,:]\n",
    "        arr[:,1:] = arr[:,1:] | arr[:,:-1]\n",
    "        arr[:,:-1] = arr[:,1:] | arr[:,:-1]\n",
    "    return arr\n",
    "\n",
    "def local_error_estimate(image):\n",
    "    error_estimate = np.zeros(image.shape, dtype=float)\n",
    "    error_estimate[1:-1,1:-1] = (image[1:-1,1:-1] - image[1:-1,2:])**2 \\\n",
    "                                + (image[1:-1,1:-1] - image[1:-1,:-2])**2 \\\n",
    "                                + (image[1:-1,1:-1] - image[2:,1:-1])**2 \\\n",
    "                                + (image[1:-1,1:-1] - image[:-2,1:-1])**2\n",
    "    error_estimate[0,:] = error_estimate[1,:]\n",
    "    error_estimate[-1,:] = error_estimate[-2,:]\n",
    "    error_estimate[:,0] = error_estimate[:,1]\n",
    "    error_estimate[:,-1] = error_estimate[:,-2]\n",
    "    error_estimate = (error_estimate / 8.) ** 0.5\n",
    "    return error_estimate\n",
    "\n",
    "def twodeebg(intensity, bg_I, legit=None):\n",
    "    nq, nfiles = intensity.shape\n",
    "    blank = np.ones((nq, nfiles))\n",
    "    mult = np.ones(nfiles) #*blank        \n",
    "    if len(bg_I.shape) == 1:\n",
    "        bg_I = bg_I.reshape((nq,1))*blank\n",
    "    if legit is not None:\n",
    "        mult[legit.any(axis=0)] = ((intensity / bg_I * legit).sum(axis=0)/legit.sum(axis=0,dtype=float)).reshape((nfiles,))[legit.any(axis=0)]  # potential problem line\n",
    "        if np.any(~legit.any(axis=0)):\n",
    "            print \"Some spectra/timeframes are entirely deselected.  Consider re-tuning your cutoff values.\"\n",
    "    else:\n",
    "        mult = ((intensity / bg_I).mean(axis=0)).reshape((nfiles,))  # potential problem line\n",
    "    mult = mult.reshape((1,nfiles))\n",
    "    #diff = intensity - mult*bg_I\n",
    "    diff = intensity/mult - bg_I\n",
    "    return mult, diff\n",
    "\n",
    "\n",
    "def make_bg(image,mult,features):\n",
    "    nq, nfiles = image.shape\n",
    "    bg_I = np.zeros(nq)\n",
    "    mult = mult.flatten()\n",
    "    #import pdb; pdb.set_trace()\n",
    "    for ii in range(nq):\n",
    "        if features[ii,:].any():\n",
    "            bg_I[ii] = np.median((image[ii,:]/mult)[features[ii,:]])*mult.mean()\n",
    "        else:\n",
    "            bg_I[ii] = np.median((image[ii,:]/mult))*mult.mean()\n",
    "    return bg_I\n",
    "\n",
    "def tree_bg_fit_adaptive(intensity_image, func, ref, cutoff, tree_depth, max_iter=15, demonstrative=False, loc=None):\n",
    "    '''\"Demonstrative\" is like \"verbose\", but with plots instead of words.\n",
    "    \n",
    "    No value for \"loc\" means no plots saved.\n",
    "    \n",
    "    \"prediction\" nonzero for features.'''\n",
    "    nq, nfiles = intensity_image.shape\n",
    "    blank = np.ones((nq, nfiles), dtype=float)\n",
    "    qq = ref[:, 0]\n",
    "    index = np.arange(nfiles)\n",
    "    qq2d = qq.reshape(nq,1)*blank\n",
    "    X1 = (qq.reshape(nq,1)*blank).flatten()\n",
    "    X2 = (index.reshape(1,nfiles)*blank).flatten()\n",
    "    X = np.array(zip(X1,X2))\n",
    "    # find initial mad guess as to background shape, difference from background,\n",
    "    # and variance from background-like-ness\n",
    "    mult = intensity_image.mean(axis=0)\n",
    "    bg_I = np.median((intensity_image/mult[np.newaxis,:]),axis=1)*mult.mean()\n",
    "    \n",
    "    waterfall_plot(intensity_image, ref)\n",
    "    plt.plot(qq,bg_I,c='k',lw=2)\n",
    "\n",
    "    mult, diff_image = twodeebg(intensity_image, bg_I)\n",
    "\n",
    "    waterfall_plot(diff_image, ref,log=False)\n",
    "\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=tree_depth)\n",
    "    oldpredictions = []\n",
    "    \n",
    "    for ii in range(max_iter):\n",
    "        if np.isnan(diff_image).any():\n",
    "            print 'NaNs here, improve coping pls'\n",
    "        smooth_diff = medfilt(diff_image, 3)\n",
    "        error_estimate = local_error_estimate(diff_image)\n",
    "        smooth_err = medfilt(error_estimate, 3)\n",
    "        #import pdb; pdb.set_trace()\n",
    "        frame4 = (np.fabs(smooth_diff) / cutoff > smooth_err)\n",
    "        frame5 = medfilt(frame4, 3)\n",
    "        frame6 = grow(frame5, 2)\n",
    "        Y = frame6.flatten()\n",
    "        clfsol = clf.fit(X, Y)\n",
    "        prediction = (clfsol.predict(X)).reshape(nq, nfiles)\n",
    "        '''\n",
    "        # attempt to deal with unconstrained fits choosing features-only over nonfeatures-only\n",
    "        if ii == 0:\n",
    "            test_popt,test_pcov=curve_fit(func,qq2d[~prediction],intensity_image[~prediction])\n",
    "            test_bg_I = func(qq,*test_popt)\n",
    "            test_mult, test_diff_image = twodeebg(intensity_image, test_bg_I, ~prediction)\n",
    "            test_goodness_of_fit = np.abs((test_diff_image[~prediction]).mean())\n",
    "            inv_prediction = ~prediction\n",
    "            inv_popt,inv_pcov=curve_fit(func,qq2d[~inv_prediction],intensity_image[~inv_prediction])\n",
    "            inv_bg_I = func(qq,*inv_popt)\n",
    "            inv_mult, inv_diff_image = twodeebg(intensity_image, inv_bg_I, ~inv_prediction)\n",
    "            inv_goodness_of_fit = np.abs((inv_diff_image[~inv_prediction]).mean())\n",
    "            if inv_goodness_of_fit < test_goodness_of_fit:\n",
    "                prediction = ~prediction\n",
    "                print \"right side up switched\"\n",
    "            else:\n",
    "                print \"orientation maintained\"\n",
    "        '''\n",
    "        metrics = []\n",
    "        for jj in oldpredictions:\n",
    "            metric = (jj != prediction).sum()\n",
    "            metrics.append(metric)\n",
    "        if ii != 0:\n",
    "            metricbest = min(metrics)\n",
    "            indexbest = metrics.index(metricbest)\n",
    "            if metricbest == 0:\n",
    "                if indexbest == (len(metrics) - 1):\n",
    "                    print \"Converged, iteration %i\" % ii\n",
    "                    suffix = \"\"\n",
    "                else:\n",
    "                    cyclelength = (len(metrics) - indexbest)\n",
    "                    print \"Cyclical convergence, iteration %i, cycle length %i\" % (ii, cyclelength)\n",
    "                    suffix = \", cycle length %i\" % cyclelength\n",
    "                    for kk in range(1, cyclelength):\n",
    "                        prediction = (prediction | oldpredictions[-kk])\n",
    "                        oldpredictions.append(prediction)\n",
    "                break\n",
    "        oldpredictions.append(prediction)\n",
    "        \n",
    "        print \"prediction mean\", prediction.mean()\n",
    "        bg_I = make_bg(intensity_image,mult,prediction)\n",
    "        mult, diff_image = twodeebg(intensity_image, bg_I, ~prediction)\n",
    "\n",
    "    if demonstrative:\n",
    "        nplots = len(oldpredictions)\n",
    "        fig, ax = plotarray(nplots)\n",
    "        flatax = ax.ravel()\n",
    "        for ii in range(nplots):\n",
    "            axii = flatax[ii]\n",
    "            if ii < nplots:\n",
    "                axii.tick_params(axis='both', which='both', bottom='off', top='off', labelbottom='off', right='off', left='off',\n",
    "                                labelleft='off')\n",
    "                axii.imshow(oldpredictions[ii].T, cmap='binary')\n",
    "                if ii != (nplots-1):\n",
    "                    axii.set_title(ii)\n",
    "                else:\n",
    "                    axii.set_title(\"Final\")\n",
    "        fig.suptitle(\"Evolution of decision tree selection\" + suffix)\n",
    "        fig2, ax2 = plt.subplots(1,2)\n",
    "        ax2[0].imshow(diff_image.T,cmap='viridis')\n",
    "        ax2[1].imshow(prediction.T,cmap='binary')\n",
    "        ax2.axis('off')\n",
    "        ax2.set_title(\"Final background-subtracted spectra, feature map\")\n",
    "        if loc is not None:\n",
    "            fname = (loc + '_dtree_bgselection_evolution.pdf')\n",
    "            fig.savefig(fname)\n",
    "            fname2 = (loc + '_diffimage_final.pdf')\n",
    "            fig2.savefig(fname2)\n",
    "        #fig.set_figheight(8)\n",
    "        #fig.set_figwidth(12)\n",
    "        #return prediction, mult, diff_image, fig, fig2\n",
    "    return prediction, mult, diff_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map1, mult1, final_diff_image1 = tree_bg_fit_adaptive(good_spectra1, quintic, ref_spec1, 3., 5, demonstrative=True, loc=loc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map3, mult3, final_diff_image3 = tree_bg_fit_adaptive(good_spectra3, quintic, ref_spec3, 1.5, 5, demonstrative=True, loc=loc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Below:  Write-out code to transfer data to Sam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writable_timeseries(spectra,qq=None,indices=None):\n",
    "    nq, nfiles = spectra.shape\n",
    "    if qq is None:\n",
    "        writable = np.zeros((nq+1,nfiles),dtype=float)\n",
    "    else:\n",
    "        writable = np.zeros((nq+1,nfiles+1),dtype=float)\n",
    "        writable[1:,0] = qq\n",
    "        \n",
    "    if (qq is not None) and (indices is not None):\n",
    "        writable[0,0] = np.nan\n",
    "    if indices is None:\n",
    "        index = np.arange(nfiles)\n",
    "    else:\n",
    "        index = indices        \n",
    "    if qq is None:\n",
    "        writable[0,:] = index\n",
    "    else:\n",
    "        writable[0,1:] = index\n",
    "    writable[-nq:,-nfiles:] = spectra\n",
    "    return writable\n",
    "\n",
    "outloc = '/Users/Amanda/Dropbox/Sam_data_20170316/supporting/Sam_20170316_csvs/'\n",
    "\n",
    "fname = outloc+'Full_time_series/Rxn1_full_series.csv'\n",
    "writable = writable_timeseries(good_spectra1,ref_spec1.T[0,:],kept_indices[0])\n",
    "np.savetxt(fname, writable.T, fmt='%.18f', delimiter=',', newline='\\n')\n",
    "fname = outloc+'Full_time_series/Rxn3_full_series.csv'\n",
    "writable = writable_timeseries(good_spectra3,ref_spec3.T[0,:])\n",
    "np.savetxt(fname, writable.T, fmt='%.18f', delimiter=',', newline='\\n')\n",
    "\n",
    "fname = outloc+'Local_subtracted_segments/Rxn1_q_3_2.csv'\n",
    "writable = writable_timeseries(subtracted_regions1[0][1],subtracted_regions1[0][0],kept_indices[0])\n",
    "np.savetxt(fname, writable.T, fmt='%.18f', delimiter=',', newline='\\n')\n",
    "fname = outloc+'Local_subtracted_segments/Rxn1_q_3_6.csv'\n",
    "writable = writable_timeseries(subtracted_regions1[1][1],subtracted_regions1[1][0],kept_indices[0])\n",
    "np.savetxt(fname, writable.T, fmt='%.18f', delimiter=',', newline='\\n')\n",
    "fname = outloc+'Local_subtracted_segments/Rxn3_q_2_7.csv'\n",
    "writable = writable_timeseries(subtracted_regions3[0][1],subtracted_regions3[0][0])\n",
    "np.savetxt(fname, writable.T, fmt='%.18f', delimiter=',', newline='\\n')\n",
    "fname = outloc+'Local_subtracted_segments/Rxn3_q_3_2.csv'\n",
    "writable = writable_timeseries(subtracted_regions3[1][1],subtracted_regions3[1][0])\n",
    "np.savetxt(fname, writable.T, fmt='%.18f', delimiter=',', newline='\\n')\n",
    "fname = outloc+'Local_subtracted_segments/Rxn3_q_4_5.csv'\n",
    "writable = writable_timeseries(subtracted_regions3[2][1],subtracted_regions3[2][0])\n",
    "np.savetxt(fname, writable.T, fmt='%.18f', delimiter=',', newline='\\n')\n",
    "\n",
    "fname = outloc+'Fit_traces/Rxn1_q_3_2_fit.csv'\n",
    "writable = writable_timeseries(fit_image_1_0,subtracted_regions1[0][0],kept_indices[0])\n",
    "np.savetxt(fname, writable.T, fmt='%.18f', delimiter=',', newline='\\n')\n",
    "fname = outloc+'Fit_traces/Rxn1_q_3_6_fit.csv'\n",
    "writable = writable_timeseries(fit_image_1_1,subtracted_regions1[1][0],kept_indices[0])\n",
    "np.savetxt(fname, writable.T, fmt='%.18f', delimiter=',', newline='\\n')\n",
    "fname = outloc+'Fit_traces/Rxn3_q_2_7_fit.csv'\n",
    "writable = writable_timeseries(fit_image_3_0,subtracted_regions3[0][0])\n",
    "np.savetxt(fname, writable.T, fmt='%.18f', delimiter=',', newline='\\n')\n",
    "fname = outloc+'Fit_traces/Rxn3_q_3_2_fit_A.csv'\n",
    "writable = writable_timeseries(fit_image_3_1a,subtracted_regions3[1][0])\n",
    "np.savetxt(fname, writable.T, fmt='%.18f', delimiter=',', newline='\\n')\n",
    "fname = outloc+'Fit_traces/Rxn3_q_3_2_fit_B.csv'\n",
    "writable = writable_timeseries(fit_image_3_1b,subtracted_regions3[1][0])\n",
    "np.savetxt(fname, writable.T, fmt='%.18f', delimiter=',', newline='\\n')\n",
    "fname = outloc+'Fit_traces/Rxn3_q_3_2_fit_C.csv'\n",
    "writable = writable_timeseries(fit_image_3_1c,subtracted_regions3[1][0])\n",
    "np.savetxt(fname, writable.T, fmt='%.18f', delimiter=',', newline='\\n')\n",
    "fname = outloc+'Fit_traces/Rxn3_q_4_5_fit.csv'\n",
    "writable = writable_timeseries(fit_image_3_2,subtracted_regions3[2][0])\n",
    "np.savetxt(fname, writable.T, fmt='%.18f', delimiter=',', newline='\\n')\n",
    "\n",
    "head1 = '\\t, peak intensity 1, q centroid 1, sigma width 1'\n",
    "head2 = head1 + ', peak intensity 2, q centroid 2, sigma width 2'\n",
    "head3 = head2 + ', peak intensity 3, q centroid 3, sigma width 3'\n",
    "\n",
    "fname = outloc+'Fit_parameters/Rxn1_q_3_2_params.csv'\n",
    "writable = writable_timeseries(fit_record_1_0,None,kept_indices[0])\n",
    "np.savetxt(fname, writable.T, fmt='%.18f', delimiter=',', newline='\\n', header=head1)\n",
    "fname = outloc+'Fit_parameters/Rxn1_q_3_6_params.csv'\n",
    "writable = writable_timeseries(fit_record_1_1,None,kept_indices[0])\n",
    "np.savetxt(fname, writable.T, fmt='%.18f', delimiter=',', newline='\\n', header=head1)\n",
    "fname = outloc+'Fit_parameters/Rxn3_q_2_7_params.csv'\n",
    "writable = writable_timeseries(fit_record_3_0)\n",
    "np.savetxt(fname, writable.T, fmt='%.18f', delimiter=',', newline='\\n', header=head1)\n",
    "fname = outloc+'Fit_parameters/Rxn3_q_3_2_params_A.csv'\n",
    "writable = writable_timeseries(fit_record_3_1a)\n",
    "np.savetxt(fname, writable.T, fmt='%.18f', delimiter=',', newline='\\n', header=head1)\n",
    "fname = outloc+'Fit_parameters/Rxn3_q_3_2_params_B.csv'\n",
    "writable = writable_timeseries(fit_record_3_1b)\n",
    "np.savetxt(fname, writable.T, fmt='%.18f', delimiter=',', newline='\\n', header=head2)\n",
    "fname = outloc+'Fit_parameters/Rxn3_q_3_2_params_C.csv'\n",
    "writable = writable_timeseries(fit_record_3_1c)\n",
    "np.savetxt(fname, writable.T, fmt='%.18f', delimiter=',', newline='\\n', header=head3)\n",
    "fname = outloc+'Fit_parameters/Rxn3_q_4_5_params.csv'\n",
    "writable = writable_timeseries(fit_record_3_2)\n",
    "np.savetxt(fname, writable.T, fmt='%.18f', delimiter=',', newline='\\n', header=head1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
